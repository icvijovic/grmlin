#!/usr/bin/env python
import numpy as np
import pandas as pd

import argparse

from germline_inference.clean_vdj import *
from germline_inference.germline_utils import *
import germline_inference.sequence_utils as sequence_utils


parser = argparse.ArgumentParser(description='Constructs a database of Ig V germlines.')

parser.add_argument('input_airr', metavar='input_file_path', type=str,
                    help='path to input AIRR-formatted table containing Ig sequences')

parser.add_argument('-annotate', metavar='path_to_blast_db', type=str, required=False,
                    help='path to database containing known Ig V alleles; '
                    'If omitted, called germline genes will not be annotated')

parser.add_argument('-outdir', metavar='output_directory', type=str, default='./',
                    help='output directory '
                         '(default: working directory)')

parser.add_argument('-trim_primers', metavar='path_to_primer_fasta',
                    type=str, required=False,
                    help='path to fasta file containing primers to be trimmed; '
                    'If omitted, no sequences will be trimmed')

parser.add_argument('--skip_preprocess', required=False, default=False,
                    dest='skip_preprocess', action='store_true',
                    help='if set, preprocessing steps will be skipped')

parser.add_argument('--verbose', required=False, default=False,
                    dest='verbose', action='store_true',
                    help='verbose output')

parser.add_argument('-max_log_v_evalue', metavar='float_value', type=float, required=False,
                    default=-60)

parser.add_argument('-max_log_j_evalue', metavar='float_value', type=float, required=False,
                    default=-10)

parser.add_argument('-min_v_sequence_length', metavar='float_value', type=float, required=False,
                    default=160)

parser.add_argument('-min_j_sequence_length', metavar='float_value', type=float, required=False,
                    default=20)

parser.add_argument('--allow_unproductive', required=False,
                    default=False, action = 'store_true')

parser.add_argument('--allow_missing_cdr3', required=False,
                    default=False, action = 'store_true')

parser.add_argument('--allow_ns_in_sequence', required=False,
                    default=False, action = 'store_true')

parser.add_argument('-max_primer_error', metavar='int_value', type=int, required=False, 
                    default=2)

parser.add_argument('--reverse_primers', required=False,
                    default=False, action = 'store_true')

parser.add_argument('-lineage_clustering_cutoff', metavar='float_value', type=float, required=False,
                    default=0.1)

parser.add_argument('-hierarchical_clustering_method', metavar='method', type=str, required=False,
                    default='average')

parser.add_argument('-min_germline_usage_fraction', metavar='float_value', type=float, required=False,
                    default=0.001)

parser.add_argument('-min_germline_num_lineages', metavar='float_value', type=float, required=False,
                    default=10)

parser.add_argument('-cloud_radius', metavar='float_value', type=float, required=False,
                    default=3)

parser.add_argument('-min_usage_fraction_within_cloud', metavar='float_value', type=float, required=False,
                    default=0.05)

args = parser.parse_args()

# parse i/o paths
INPUT_FILENAME = args.input_airr
outdir = args.outdir

if args.trim_primers is None:
    trim_primers = False
else:
    trim_primers = True
    primer_dict = sequence_utils.fasta_to_dict(args.trim_primers)

skip_preprocess = args.skip_preprocess
verbose = args.verbose

# preprocessing filter parameters
MAX_LOG_V_EVALUE = args.max_log_v_evalue
MAX_LOG_J_EVALUE = args.max_log_j_evalue
ALLOW_UNPRODUCTIVE = args.allow_unproductive
ALLOW_MISSING_CDR3 = args.allow_missing_cdr3
ALLOW_Ns_IN_SEQUENCE = args.allow_ns_in_sequence
MIN_V_SEQUENCE_LENGTH = args.min_v_sequence_length
MIN_J_SEQUENCE_LENGTH = args.min_j_sequence_length

#primer trimming parameters
MAX_PRIMER_ERROR = args.max_primer_error
if args.reverse_primers:
    PRIMER_ORIENTATION = 'rev'
else:
    PRIMER_ORIENTATION = 'fwd'

# clustering parameters
LINEAGE_CLUSTERING_CUTOFF = args.lineage_clustering_cutoff
CLUSTERING_METHOD = args.hierarchical_clustering_method

# germline calling parameters
MIN_GERMLINE_USAGE_FRACTION = args.min_germline_usage_fraction
MIN_GERMLINE_NUM_LINEAGES = args.min_germline_num_lineages
CLOUD_RADIUS = args.cloud_radius
MIN_USAGE_FRAC_WITHIN_CLOUD = args.min_usage_fraction_within_cloud

sample_name = INPUT_FILENAME.split("/")[-1].split(".tsv.gz")[0]

if __name__ == '__main__':

    if args.annotate is None:
        print("Warning: Existing Ig V allele database not provided. "
              "Called germline alleles will not be annotated.")

    df = pd.read_csv(INPUT_FILENAME, sep='\t').dropna(how='all', axis=1)
    
    if not skip_preprocess:
        # ensure that all sequences pass QC criteria
        df = clean_vdj_dataframe(df,
                                 MAX_LOG_V_EVALUE=MAX_LOG_V_EVALUE,
                                 MAX_LOG_J_EVALUE=MAX_LOG_J_EVALUE,
                                 ALLOW_UNPRODUCTIVE=ALLOW_UNPRODUCTIVE,
                                 ALLOW_MISSING_CDR3=ALLOW_MISSING_CDR3,
                                 ALLOW_Ns_IN_SEQUENCE=ALLOW_Ns_IN_SEQUENCE,
                                 MIN_V_SEQUENCE_LENGTH=MIN_V_SEQUENCE_LENGTH,
                                 MIN_J_SEQUENCE_LENGTH=MIN_J_SEQUENCE_LENGTH,
                                 verbose=verbose)

        # parse out templated v sequence
        df['v_sequence'] = df.apply(lambda x: x.sequence[int(x.v_sequence_start)-1:
                                                         int(x.cdr3_start)],
                                    axis=1)

        v_templated_col = 'v_sequence'

        if trim_primers:
            # v primers assumed in fwd orientation
            if verbose:
                print(" Trimming primers...")
            df = trim_primer_sequence(df, v_templated_col, primer_dict,
                                      primer_orientation=PRIMER_ORIENTATION,
                                      max_error=MAX_PRIMER_ERROR)
            v_templated_col = v_templated_col + "_trimmed"
            if verbose:
                print(" Done!")

        # extract v family info from v_call
        df['v_family'] = df.v_call.map(lambda x: x.split("-")[0].split("/")[0])

        # collapse truncated sequences
        v_seq_trunc_map = {}

        # for efficiency, only check whether v sequences within the same family
        # represent truncations of one another
        if verbose:
            print(" Collapsing sequences that represent truncations of one another...")
        for family in df.v_family.unique():
            family_truncation_map = construct_truncation_map(df[df.v_family == family][v_templated_col])
            v_seq_trunc_map.update(family_truncation_map)
        if verbose: 
            print(" Done!")

        df[v_templated_col+"_no_trunc"] = df[v_templated_col].map(v_seq_trunc_map)
        v_templated_col = v_templated_col + "_no_trunc"  

        # cache dataframe
        cache_dest = '{}/{}_preprocessed.tsv.gz'.format(outdir, sample_name)
        if verbose:
            print(" Caching cleaned AIRR dataframe, see {}".format(cache_dest))

        df.to_csv(cache_dest, sep='\t')               
        
    else:
        v_templated_col = [x for x in df.columns if x.endswith("no_trunc")]
        if len(v_templated_col) != 1:
            raise KeyError("Failed to identify column containing cleaned sequences."
                           " Expected exactly one column of dataframe to end with string 'no_trunc'")
        v_templated_col = v_templated_col[0]

        # avoid renaming sample
        if sample_name.endswith("preprocessed"):
            sample_name = sample_name.split("_preprocessed")[0]

    # extract multilineage v sequence info
    multilin_vs, cdr3_dists_v = extract_multilineage_sequences(df,
                                                             v_templated_col,
                                                             retain_columns=['v_family'],
                                                             clustering_method=CLUSTERING_METHOD,
                                                             clustering_cutoff=LINEAGE_CLUSTERING_CUTOFF)
    # cache multilineage sequences and cdr3 distribution
    multinlin_v_dest = "{}/{}_multilineage_vs.tsv.gz".format(outdir, sample_name)
    cdr3_dists_v_dest = "{}/{}_cdr3_distance_distribution.tsv.gz".format(outdir, sample_name)
   
    if verbose:
        print(" Caching information about all V sequences associated with"
              "multiple lineages, see:\n{}\n{}".format(multinlin_v_dest, cdr3_dists_v_dest))

    multilin_vs.to_csv(multinlin_v_dest, sep='\t')
    pd.Series(cdr3_dists_v).to_csv(cdr3_dists_v_dest, sep='\t')

    # call v germlines
    v_germline_df = call_germline_genes(multilin_vs,
                                        MIN_FRACTION=MIN_GERMLINE_USAGE_FRACTION,
                                        MIN_NUMBER=MIN_GERMLINE_NUM_LINEAGES,
                                        CLOUD_RADIUS=CLOUD_RADIUS,
                                        MIN_USAGE_FRAC_WITHIN_CLOUD=MIN_USAGE_FRAC_WITHIN_CLOUD,
                                        verbose=verbose)
    # annotate v germlines
    if args.annotate is None:
        pass
    else:
        if v_germline_df.shape[0] > 0:
            v_germline_df = annotate_germline_calls(v_germline_df, args.annotate)
        else:
            v_germline_df = pd.DataFrame({v_templated_col:[],'match':[],'btop':[],'mutations':[]}) 
    if verbose:
      print(" Called a total of {n} germline alleles. ".format(n = v_germline_df.shape[0]))
      if not (args.annotate is None):
        print(" {m} of these can be mapped to alleles in provided database.".format(
              m = v_germline_df.match.notna().sum()))

    # print germline_calls
    germline_dest = "{}/{}_v_germlines.tsv".format(outdir, sample_name)

    print(" Saving germline allele information to: {}".format(germline_dest))

    v_germline_df = v_germline_df.rename(columns={v_templated_col: 'sequence',
                                                  'match':'db_call'})
    v_germline_df.to_csv(germline_dest, sep='\t')
